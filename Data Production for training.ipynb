{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5314c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0246768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"outputxNew.csv\").to_numpy()\n",
    "y_train = pd.read_csv(\"outputyNew.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc27a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94630595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = pd.read_csv(\"tweets.csv\")\n",
    "# tweetI = pd.read_csv(\"tweet-index.csv\")\n",
    "df = pd.read_csv(\"AMZN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70dd18cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>37.896000</td>\n",
       "      <td>37.938000</td>\n",
       "      <td>37.384998</td>\n",
       "      <td>37.683498</td>\n",
       "      <td>37.683498</td>\n",
       "      <td>70422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>37.919498</td>\n",
       "      <td>37.984001</td>\n",
       "      <td>37.709999</td>\n",
       "      <td>37.859001</td>\n",
       "      <td>37.859001</td>\n",
       "      <td>50210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>38.077499</td>\n",
       "      <td>39.119999</td>\n",
       "      <td>38.013000</td>\n",
       "      <td>39.022499</td>\n",
       "      <td>39.022499</td>\n",
       "      <td>116602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>39.118000</td>\n",
       "      <td>39.972000</td>\n",
       "      <td>38.924000</td>\n",
       "      <td>39.799500</td>\n",
       "      <td>39.799500</td>\n",
       "      <td>119724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>39.900002</td>\n",
       "      <td>40.088501</td>\n",
       "      <td>39.588501</td>\n",
       "      <td>39.846001</td>\n",
       "      <td>39.846001</td>\n",
       "      <td>68922000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   \n",
       "0  2017-01-03  37.896000  37.938000  37.384998  37.683498  37.683498  \\\n",
       "1  2017-01-04  37.919498  37.984001  37.709999  37.859001  37.859001   \n",
       "2  2017-01-05  38.077499  39.119999  38.013000  39.022499  39.022499   \n",
       "3  2017-01-06  39.118000  39.972000  38.924000  39.799500  39.799500   \n",
       "4  2017-01-09  39.900002  40.088501  39.588501  39.846001  39.846001   \n",
       "\n",
       "      Volume  \n",
       "0   70422000  \n",
       "1   50210000  \n",
       "2  116602000  \n",
       "3  119724000  \n",
       "4   68922000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5bdd7c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '2015-01-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweets\u001b[38;5;241m.\u001b[39mpost_date:\n\u001b[0;32m----> 4\u001b[0m     tweets\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mutcfromtimestamp(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtweets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     i \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '2015-01-01'"
     ]
    }
   ],
   "source": [
    "tweets.post_date = tweets.post_date.astype(str)\n",
    "i = 0\n",
    "for tweet in tweets.post_date:\n",
    "    tweets.loc[i, 'post_date'] = datetime.utcfromtimestamp(int(tweets.loc[i, 'post_date'])).strftime('%Y-%m-%d')\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a08595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(tweets, tweetI, how='inner', on='tweet_id')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('merged_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f10b2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedFile = pd.read_csv(\"merged_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209ebf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashutoshsingh/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94800e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecd736c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst):\n",
    "    \"\"\"\n",
    "    Flattens a 2D list into a 1D list.\n",
    "    \"\"\"\n",
    "    flattened = []\n",
    "    for sublist in lst:\n",
    "        for item in sublist:\n",
    "            flattened.append(item)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c62d312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"2018-08-30\", \"2018-08-15\",\"2018-07-30\",\"2018-07-15\",\"2018-06-30\",\"2018-06-15\",\"2018-05-30\",\"2018-05-15\",\"2018-04-30\",\"2018-04-15\",\n",
    "\"2017-08-30\", \"2017-08-15\",\"2017-07-30\",\"2017-07-15\",\"2017-06-30\",\"2017-06-15\",\"2017-05-30\",\"2017-05-15\",\"2017-04-30\",\"2017-04-15\"]\n",
    "x_train = []\n",
    "y_train = []\n",
    "for targetDate in dates:\n",
    "    target_date = pd.to_datetime(targetDate)\n",
    "    one_week_before = target_date - timedelta(days=7)\n",
    "    one_week_before = one_week_before.strftime('%Y-%m-%d')\n",
    "    start_value = one_week_before\n",
    "    end_value = targetDate\n",
    "    # Use boolean indexing to select tuples that fall within the specified range\n",
    "    resultPart = mergedFile[(mergedFile['post_date'] >= start_value) & (mergedFile['post_date'] <= end_value)]\n",
    "    resultCompany = resultPart[resultPart['ticker_symbol'] == \"AMZN\"]\n",
    "    resultCompany = resultCompany.sort_values('retweet_num', ascending=False)\n",
    "    resultCompany = resultCompany.head(200)\n",
    "    # tweetsOb = result['body']\n",
    "    tweetsOb = resultCompany['body'].values\n",
    "    retweetsOb = resultCompany['retweet_num'].values\n",
    "    commentOb = resultCompany['comment_num'].values\n",
    "    likeOb = resultCompany['like_num'].values\n",
    "    \n",
    "    daysOb = [(datetime.strptime(targetDate, \"%Y-%m-%d\")-datetime.strptime(date2, \"%Y-%m-%d\")).days for date2 in resultCompany['post_date']]\n",
    "    \n",
    "    sentiResult = nlp(tweetsOb.tolist())\n",
    "    labels = [{\"positive\":0,\"neutral\":0,\"negative\":0} for i in sentiResult]\n",
    "    i =0\n",
    "    for obj in sentiResult:\n",
    "        (labels[i])[obj['label']] = obj['score']\n",
    "        i=i+1\n",
    "    positive = [elem['positive'] for elem in labels]\n",
    "    negative = [elem['negative'] for elem in labels]\n",
    "    neutral = [elem['neutral'] for elem in labels]\n",
    "    \n",
    "    labels = [int(i['label'].split()[0]) for i in sentimentResult]\n",
    "    xComp = [[a,b,c,d,e,f,g] for a,b,c,d,e,f,g in zip(positive, negative, neutral, retweetsOb, commentOb, likeOb, daysOb)]    \n",
    "#     xComp = flatten(xComp)\n",
    "\n",
    "    stockTargetDate = target_date + timedelta(days=1)\n",
    "    six_days_before = stockTargetDate - timedelta(days=6)\n",
    "    six_days_before = six_days_before.strftime('%Y-%m-%d')\n",
    "\n",
    "    start_value = six_days_before\n",
    "    end_value = stockTargetDate.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Use boolean indexing to select tuples that fall within the specified range\n",
    "    st = df[(df['Date'] >= start_value) & (df['Date'] <= end_value)]\n",
    "    diff = st.Close.tolist()[-1] - st.Open.tolist()[0]\n",
    "    delta = diff / st.Open.tolist()[0]\n",
    "    delta\n",
    "    for elem in xComp:\n",
    "        x_train.append(elem)\n",
    "        y_train.append(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7fdb884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 7)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb8cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d712fac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05102348, 0.05102348, 0.05102348, 0.05102348, 0.05102348])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f83b33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b125d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4175c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "\n",
    "xDf = pd.DataFrame(x_train, columns=['A', 'B', 'C','D','E','F','G'])\n",
    "yDf = pd.DataFrame(y_train.tolist(), columns=['values'])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "xDf.to_csv('outputxNew.csv', index=False)\n",
    "yDf.to_csv('outputyNew.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf4abc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920105</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.539348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903385</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904519</td>\n",
       "      <td>57.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744008</td>\n",
       "      <td>55.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902423</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939989</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551905</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923244</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.943658</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A    B         C     D     E      F    G\n",
       "0     0.000000  0.0  0.920105  88.0   4.0  125.0  1.0\n",
       "1     0.539348  0.0  0.000000  77.0   7.0  321.0  2.0\n",
       "2     0.000000  0.0  0.903385  59.0   8.0  147.0  1.0\n",
       "3     0.000000  0.0  0.904519  57.0  27.0   71.0  1.0\n",
       "4     0.000000  0.0  0.744008  55.0  17.0   73.0  1.0\n",
       "...        ...  ...       ...   ...   ...    ...  ...\n",
       "3995  0.000000  0.0  0.902423   2.0   1.0    6.0  3.0\n",
       "3996  0.000000  0.0  0.939989   2.0   0.0    0.0  1.0\n",
       "3997  0.000000  0.0  0.551905   2.0   1.0    4.0  6.0\n",
       "3998  0.000000  0.0  0.923244   2.0   0.0    7.0  7.0\n",
       "3999  0.000000  0.0  0.943658   2.0   2.0    4.0  3.0\n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c13cb92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Values\n",
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "3       4\n",
      "4       5\n"
     ]
    }
   ],
   "source": [
    "my_array = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Convert array to dataframe\n",
    "newdf = pd.DataFrame(my_array, columns=['Values'])\n",
    "\n",
    "# Display dataframe\n",
    "print(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5532ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 22:28:05.776347: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 6s 1ms/step - loss: 3.4653e-04\n",
      "Epoch 2/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.0994e-04\n",
      "Epoch 3/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 6.5852e-05\n",
      "Epoch 4/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 5.7517e-05\n",
      "Epoch 5/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 4.6881e-05\n",
      "Epoch 6/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 4.3553e-05\n",
      "Epoch 7/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 4.0463e-05\n",
      "Epoch 8/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.7669e-05\n",
      "Epoch 9/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 3.5239e-05\n",
      "Epoch 10/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.4465e-05\n",
      "Epoch 11/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.3403e-05\n",
      "Epoch 12/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.2522e-05\n",
      "Epoch 13/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 3.1736e-05\n",
      "Epoch 14/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.1196e-05\n",
      "Epoch 15/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.0587e-05\n",
      "Epoch 16/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.0186e-05\n",
      "Epoch 17/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9670e-05\n",
      "Epoch 18/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9579e-05\n",
      "Epoch 19/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9737e-05\n",
      "Epoch 20/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9558e-05\n",
      "Epoch 21/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 3.0007e-05\n",
      "Epoch 22/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9585e-05\n",
      "Epoch 23/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9385e-05\n",
      "Epoch 24/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 3.0170e-05\n",
      "Epoch 25/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9680e-05\n",
      "Epoch 26/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9407e-05\n",
      "Epoch 27/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9726e-05\n",
      "Epoch 28/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9818e-05\n",
      "Epoch 29/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9728e-05\n",
      "Epoch 30/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9935e-05\n",
      "Epoch 31/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9639e-05\n",
      "Epoch 32/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9796e-05\n",
      "Epoch 33/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9440e-05\n",
      "Epoch 34/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9570e-05\n",
      "Epoch 35/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9724e-05\n",
      "Epoch 36/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9794e-05\n",
      "Epoch 37/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9770e-05\n",
      "Epoch 38/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9932e-05\n",
      "Epoch 39/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.0058e-05\n",
      "Epoch 40/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9465e-05\n",
      "Epoch 41/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9822e-05\n",
      "Epoch 42/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9600e-05\n",
      "Epoch 43/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9553e-05\n",
      "Epoch 44/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9510e-05\n",
      "Epoch 45/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9765e-05\n",
      "Epoch 46/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9402e-05\n",
      "Epoch 47/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9830e-05\n",
      "Epoch 48/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9852e-05\n",
      "Epoch 49/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9626e-05\n",
      "Epoch 50/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9916e-05\n",
      "Epoch 51/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9707e-05\n",
      "Epoch 52/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9696e-05\n",
      "Epoch 53/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9885e-05\n",
      "Epoch 54/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9646e-05\n",
      "Epoch 55/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9415e-05\n",
      "Epoch 56/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9549e-05\n",
      "Epoch 57/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9201e-05\n",
      "Epoch 58/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9971e-05\n",
      "Epoch 59/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9753e-05\n",
      "Epoch 60/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9815e-05\n",
      "Epoch 61/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9598e-05\n",
      "Epoch 62/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9695e-05\n",
      "Epoch 63/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9967e-05\n",
      "Epoch 64/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9693e-05\n",
      "Epoch 65/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9442e-05\n",
      "Epoch 66/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9860e-05\n",
      "Epoch 67/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9633e-05\n",
      "Epoch 68/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9678e-05\n",
      "Epoch 69/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9675e-05\n",
      "Epoch 70/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9196e-05\n",
      "Epoch 71/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9906e-05\n",
      "Epoch 72/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9799e-05\n",
      "Epoch 73/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9694e-05\n",
      "Epoch 74/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9445e-05\n",
      "Epoch 75/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9855e-05\n",
      "Epoch 76/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9528e-05\n",
      "Epoch 77/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 3.0133e-05\n",
      "Epoch 78/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9420e-05\n",
      "Epoch 79/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9337e-05\n",
      "Epoch 80/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9924e-05\n",
      "Epoch 81/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9609e-05\n",
      "Epoch 82/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9332e-05\n",
      "Epoch 83/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9781e-05\n",
      "Epoch 84/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9758e-05\n",
      "Epoch 85/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 3.0205e-05\n",
      "Epoch 86/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9451e-05\n",
      "Epoch 87/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9716e-05\n",
      "Epoch 88/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9782e-05\n",
      "Epoch 89/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9655e-05\n",
      "Epoch 90/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9762e-05\n",
      "Epoch 91/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9715e-05\n",
      "Epoch 92/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9784e-05\n",
      "Epoch 93/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9890e-05\n",
      "Epoch 94/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9679e-05\n",
      "Epoch 95/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9301e-05\n",
      "Epoch 96/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9683e-05\n",
      "Epoch 97/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9587e-05\n",
      "Epoch 98/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 2.9657e-05\n",
      "Epoch 99/100\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 2.9683e-05\n",
      "Epoch 100/100\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 3.0008e-05\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 30\u001b[0m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(dummyX, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Once the model is trained, you can use it to make predictions on new data\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Prepare your new data for prediction (assuming x_test is your new data)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# x_test = np.array([[0.0, 0.0, 0.8157535195350647, 27.0, 7.0, 82.0, 1.0],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#                    [0.0, 0.0, 0.8958992958068848, 23.0, 0.0, 28.0, 6.0],\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#                    [0.0, 0.0, 0.8829037547111511, 22.0, 3.0, 115.0, 4.0]])\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m x_test \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m(\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     31\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(x_test, (x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define your LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(7, 1)))  # 7 features, 1 time step\n",
    "model.add(Dense(1))  # Output layer with single node for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Prepare your data\n",
    "dummyX = x_train\n",
    "dummyY = y_train\n",
    "# Reshape x_train to have 3D shape (samples, time steps, features)\n",
    "dummyX = np.reshape(dummyX, (dummyX.shape[0], dummyX.shape[1], 1))\n",
    "\n",
    "# Train the LSTM model\n",
    "model.fit(dummyX, y_train, epochs=100, batch_size=1)\n",
    "\n",
    "# Once the model is trained, you can use it to make predictions on new data\n",
    "# Prepare your new data for prediction (assuming x_test is your new data)\n",
    "# x_test = np.array([[0.0, 0.0, 0.8157535195350647, 27.0, 7.0, 82.0, 1.0],\n",
    "#                    [0.0, 0.0, 0.9311531782150269, 26.0, 0.0, 26.0, 4.0],\n",
    "#                    [0.0, 0.0, 0.9164313077926636, 24.0, 0.0, 25.0, 6.0],\n",
    "#                    [0.0, 0.0, 0.8958992958068848, 23.0, 0.0, 28.0, 6.0],\n",
    "#                    [0.0, 0.0, 0.8829037547111511, 22.0, 3.0, 115.0, 4.0]])\n",
    "x_test = x_train.head(20)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "y_pred = model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "574a6640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 899us/step\n"
     ]
    }
   ],
   "source": [
    "x_test = x_train\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ae2d820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00291349],\n",
       "       [0.00213732],\n",
       "       [0.00291355],\n",
       "       ...,\n",
       "       [0.00142697],\n",
       "       [0.00142368],\n",
       "       [0.0014895 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "014607ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00850391, 0.00850391, 0.00850391, 0.00850391, 0.00850391,\n",
       "       0.00850391, 0.00850391, 0.00850391, 0.00850391, 0.00850391,\n",
       "       0.00850391, 0.00850391, 0.00850391, 0.00850391, 0.00850391,\n",
       "       0.00850391, 0.00850391, 0.00850391, 0.00850391, 0.00850391])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "57b3aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(actual,predicted):\n",
    "    fails = 0;\n",
    "    passes = 0;\n",
    "    for i, j in zip(actual,predicted):\n",
    "        if(i*j<0):\n",
    "            fails=fails+1\n",
    "        else:\n",
    "            passes=passes+1\n",
    "    return passes/(passes+fails)\n",
    "\n",
    "# def Accuracy(actual,predicted):\n",
    "#     sums = 0\n",
    "#     for i, j in zip(actual,predicted):\n",
    "#         sums  = sums+abs(i-j)\n",
    "#     return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c319d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.816014], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy(y_train,y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "700fa833",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dummyY\n",
    "\n",
    "newY_train = y_train[::200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4a142071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newY_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "067e1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyX = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "87c15351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 11ms/step - loss: 0.0190\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0200\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0057\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0025\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0015\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0015\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0013\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0023\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 4.8678e-04\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 9.3204e-04\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.7721e-04\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.4560e-04\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.8681e-04\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.0157e-04\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.3484e-04\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.0615e-04\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.9699e-04\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.3855e-04\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.6877e-04\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.7129e-04\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.6597e-04\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.5344e-04\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.6711e-04\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.3868e-04\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.0536e-04\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 4.0642e-04\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.8528e-04\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.0194e-04\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.4850e-04\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.4667e-04\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.7899e-04\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.1448e-04\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.5745e-04\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.7562e-04\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 4.7114e-04\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.2043e-04\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 9.7424e-04\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0014\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0010\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0011\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0022\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0044\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0085\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0043\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 8.4238e-04\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 4.8044e-04\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.0452e-04\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.2531e-04\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.0744e-04\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 9.9252e-05\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 5.9608e-05\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 9.9081e-05\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 8.4497e-05\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.2007e-05\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.5055e-05\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.7084e-05\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.8488e-05\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.4300e-05\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.8314e-05\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.5698e-05\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.1294e-05\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.8202e-06\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 8.7208e-06\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 4.3210e-06\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 9.5315e-06\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 9.1345e-06\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.9151e-06\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.1418e-06\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 4.7364e-06\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.8579e-06\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.2599e-06\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.9975e-06\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.8387e-06\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 4.3491e-06\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.8381e-06\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 7.5860e-06\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.6780e-06\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.0676e-05\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 9.8559e-06\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.1157e-05\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.7472e-05\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.8821e-05\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.2517e-05\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 9.1654e-05\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.0206e-04\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 2.3474e-04\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 3.6227e-04\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 7.0786e-04\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.8283e-04\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0011\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0036\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0029\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0038\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0022\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 8.3849e-04\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 5.1165e-04\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 5.1232e-04\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 6.1701e-04\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 6.2625e-04\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.2461e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3527bf790>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate dummy input data with shape (20, 200, 7)\n",
    "input_data = reshaped_input_data\n",
    "\n",
    "# Generate dummy target data with shape (20,)\n",
    "target_data = newY_train\n",
    "\n",
    "# Define your LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(200, 7)))  # 200 time steps, 7 features\n",
    "model.add(Dense(1))  # Output layer with single node for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the LSTM model\n",
    "model.fit(input_data, target_data, epochs=100, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3a86b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(reshaped_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54dc9e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAccuracy\u001b[49m(pred,newY_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "Accuracy(pred,newY_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f19432b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00850391, -0.00017563, -0.00472493,  0.00804894, -0.00026531,\n",
       "        0.00341558,  0.00276773, -0.0021967 ,  0.01420438,  0.00110684,\n",
       "        0.0042887 ,  0.00032094, -0.00807122,  0.00284433, -0.0066931 ,\n",
       "        0.00356947,  0.00165338,  0.00219718,  0.00756857, -0.0027715 ])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newY_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b1965934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1451561e-02],\n",
       "       [ 1.0207165e-02],\n",
       "       [-4.6559498e-03],\n",
       "       [ 6.6161640e-03],\n",
       "       [ 9.9096708e-03],\n",
       "       [ 1.7795287e-02],\n",
       "       [ 8.9471526e-03],\n",
       "       [-2.8177747e-04],\n",
       "       [ 1.3870038e-02],\n",
       "       [ 2.0165851e-03],\n",
       "       [ 8.6123846e-04],\n",
       "       [-7.7266479e-05],\n",
       "       [ 1.9711812e-03],\n",
       "       [ 4.1658692e-03],\n",
       "       [-2.2750627e-02],\n",
       "       [ 6.6922791e-03],\n",
       "       [-2.0249795e-02],\n",
       "       [ 1.2775488e-02],\n",
       "       [ 1.1208180e-02],\n",
       "       [-7.0879720e-03]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98b223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "num_timesteps = 200\n",
    "num_features = 7\n",
    "\n",
    "reshaped_input_data = np.zeros((num_samples, num_timesteps, num_features))\n",
    "for i in range(num_samples):\n",
    "    reshaped_input_data[i] = x_train[i*num_timesteps:(i+1)*num_timesteps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1372f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f2ff3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LSTM-Final.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06d8a65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3994,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7fcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
